---
layout:     post
title:      Lecture Series on Deep Reinforcement Learning
date:       2017-11-21
summary:    Series of three lectures at NTNU covering the building blocks, recent advances, challenges, and applications of deep reinforcement learning.
categories: lecture
---

In Autumn 2017, I had the previlige of doing a [series of lectures on deep reinforcement learning (deep RL)](https://www.ntnu.edu/web/ailab/dl_tutorial) at [NTNU, Trondheim](https://www.ntnu.edu/). This was open to the public, but mostly attended by students studying AI in some form at NTNU. Covering the basics of RL, recent advances, and challenges that the RL research community deals with, all in just 3 lectures, is an exciting prospect. 

<div class="img_container">
![]({{site.baseurl}}/images/drl-tutorial2017.png){: width=100%}<br>
</div>

It took quite some preperation, and was somewhat exhausting, but hey, I can safely say that I managed to desig and deliver a *bootcamp* of sorts on deep RL. But that is not the point. The point is to inspire curiosity amongst students, and hope that some would join in the effort to advance RL. It was immensely rewarding. 

Below is what we covered.


## Lecture 1: Introduction and state-of-the-art

*24 October 2017, 16:00-18:00 at Gamle elektro EL3*

The first part introduced deep RL and attempted to draw a comprehensive picture of the field as it stood in Autumn 2017. Progress in the field, building up to frontiers, open technical challenges, and attempts to addressing these, were some of the things covered.

**Slides** [here]({{site.baseurl}}/slides/notes-drl-lect1.pdf). Video *forthcoming*.

## Lecture 2: Building blocks

*8 November 2017, 12:00-14:00 at Realfagbygget R9*

To make working in the field tangible for all, the second part elaborated on the building blocks of deep RL. We examined the theory and intuition behind the different classes of RL algorithms, and the use of deep models within the RL framework to scale these algorithms. This was done in light of the building blocks so as to inspire the creative pursuit of composing novel agent architectures and training regimens for solving sequential decision making problems.

**Slides** [here]({{site.baseurl}}/slides/notes-drl-lect2.pdf). Video *forthcoming*.

## Lecture 3: Applications

*21 November 2017, 14:00-16:00 at Sentralbygg 1 S1*

We framed various real world control problems as sequential decision making problems, and examined how deep RL provides a fitting solution to these. We also went through some code covering value and policy based methods. The **[code](https://github.com/traai/drl-tutorial)** can be found here. Some exercises that encourage extending the provided code to capture a number of ideas from the previous lecture, which make the algorithms more efficient, were also provided.

**Slides** [here]({{site.baseurl}}/slides/notes-drl-lect3.pdf). We *did not* record this session.

Ongoing rapid advancements in the field can be overwhelming for students just stepping in to deep RL. Bringing some order here for them to navigate the field better, thereby enabling them to take on some of the outstanding challenges, is most exciting. Thanks are due to both [Telenor Research](https://www.telenor.com/innovation/research/) and the [Telenor-NTNU AI Lab](https://www.ntnu.edu/web/ailab/) for supporting me in this endeavour.